---
title: "BEE552 Biometry Week 4"
author: "Maria Feiler"
date: "2/16/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(MASS)
library(data.table)
library(dplyr)
library(knitr)
```

## My Learning Journey

*Over the last week, I participated in Biometry in the following ways:*

- I asked / answered **5** questions posed in class.

- I asked **0** questions in Slack.

- I answered **1** questions posed by other students on Slack.

- I came to Heather's office hours: **No**

- I came to Jose's office hours: **No**

- I met with Heather or Jose separately from office hours: **No**

*Anything not falling into one of the above categories?*  

> **No**

*On a scale of 1 (no knowledge) to 10 (complete expert), how would I rate my* 
*comfort with R programming after this week?* 

> **6**

*Any topics from last week that you are still confused about?*

> **Doing fine for now**

\newpage

## Problem Set 

### Part I
*We will be using a recently published dataset on ancient rings and ribs that may have been used as early forms of money. These data come from the paper “The origins of money: Calculation of similarity indexes demonstrates the earliest development of commodity money in prehistoric Central Europe” by M.H.G. Kuijpers and C. Popa (PLoS ONE, January 20, 2021).*

*Download the data in the file “rings_and_ribs.csv”.*

```{r money}
money <- read_excel("journal.pone.0240462.s002.xlsx",
                    sheet = 1
                    )

# Rename the weight column to make it tidy
money <- rename(money, Weight = `Weight (g)`)
```

\tiny
```{r money display, echo = FALSE, comment = NA, cache = TRUE}
kable(as.data.frame(money[sample(seq(1, length(money$Location)), 30, replace = FALSE),]),
      caption = "A selection of data from Kuijpers and Popa 2021.",
      row.names = FALSE
      )

```

\normalsize

\newpage

#### Question 1
*For now, let’s group all the locations together. Make a histogram of ring weight.*

```{r p1q1, echo = FALSE}
hist(money$Weight[money$Type == "Ring"],
    main = "Ring Weights",
    breaks = 30, 
    xlab = "Weight (g)"
    )
```

#### Question 2
*What is the FORMULA for the sample mean and standard deviation (in other words, what is the formula you would want to use if you wanted to estimate the population mean [the $\mu$ parameter assuming a normal distribution] and the population variance [$\sigma^2$  if we assume a normal distribution] from a sample that represented a random subset of the entire population)?*

$$
\begin{aligned}
\overline{X} &= \frac{\sum^{n}_{i=1}X_i}{n} \\
S &= \sqrt{\frac{\sum^{n}_{i=1}(X_i - \overline{X})^2}{n-1}}
\end{aligned}
$$

#### Question 3
*What is the population about which we are trying to make inference?*

> The population is the total collection of rings and ribs ever used for currency in the context of Germany, Austria, the Czech Republic, and Poland during this time period.

#### Question 4
*Using R, what are the mean and the standard deviation of ring weight?*

```{r p1q4, echo = FALSE, comment = FALSE}
ringMean <- mean(money["Type" = "Ring",]$Weight)

ringSD <- sd(money["Type" = "Ring",]$Weight)
```

> The mean of the ring weights is `r round(mean(money["Type" = "Ring",]$Weight), digits = 3)`. The standard deviation of ring weights is `r round(sd(money["Type" = "Ring",]$Weight), digits = 3)`.

#### Question 5
*What is the formula for the standard error of the mean (heretofore s.e.)?*

$$
SEM = \sqrt{\frac{S^{2}}{n}}
$$

#### Question 6
*Describe the difference between the s.e. (of the mean) and the s.d.*

> The standard deviation is a measure of the variance of your sample The standard error of the mean describes how close your sample mean approximates the population mean.")

#### Question 7
*Finish the sentence: The standard error is the standard deviation of...*

> ...the mean.

#### Question 8
*Use the MASS package’s ‘fitdistr’ function to fit a normal distribution to the ring weight data. Do you get the roughly same answer as above?*

```{r p1q8, comment = NA}
ringWeightFit <- fitdistr(money["Type" = "Ring",]$Weight,
                           "normal")

# Calculate difference in calculated and fitdistr() means
meandif <- unname(ringWeightFit$estimate[1]) - ringMean

# Calculate difference in calculated and fitdistr() standard deviations
sddif <- unname(ringWeightFit$estimate[2]) - ringSD

```

> The difference between the calculated mean and the mean from fitdistr() is `r round(meandif, digits = 3)` The difference between the calculated standard deviation and the standard deviation from fitdistr() is `r round(sddif, digits = 5)`.

### Question 9
*Why might it not be valid to group the different locations when summarizing the data?*

>Though there might be differences between the rings used as currency in each country, all were considered to have monetary value and might have changed hands outside of country/political entity lines. Since they are all from the same time period, if you want to characterize how the earliest money worked, you must use all the material that was used as money.

\newpage

#### Question 10
*Using the R command ‘boxplot’, create a boxplot to compare ring weight across different countries.*

```{r ringsByCountry}
ringsByCountry <- melt(data = as.data.table(money["Type" = "Ring",]), 
                       id = "Country", 
                       measure = "Weight"
                       )
```

```{r p1q10, echo = FALSE}
boxplot(value ~ Country, 
        ringsByCountry,
        ylab = "Weight (g)",
        main = "Ring Weights by Country")
```

#### Question 11
*Make the case (in words and/or mathematically) that average ring weight in Germany is or is not statistically different from the average ring weight in Austria.*

> I will test whether or not the mean weight of Austrian and German rings are statistically different using a critical value of $\alpha_{c} = 0.05$. The null hypothesis $(H_0: \overline{x}_{German} = \overline{x}_{Austrian})$ will be tested using a student's t-test and will be rejected if $p > 0.05$. 

```{r p1q11}
GermanVSAustrian <- t.test(ringsByCountry$value[ringsByCountry$Country == "Germany"],
                           ringsByCountry$value[ringsByCountry$Country == "Austria"]
                           )
```

> The average weight of Austrian rings (`r round(unname(GermanVSAustrian$estimate[2]), digits = 2)` grams) is statistically greater than the average weight of German rings (`r round(unname(GermanVSAustrian$estimate[1]), digits = 2)` grams) (p `r ifelse(GermanVSAustrian$p.value < 0.001, "< 0.001", round(GermanVSAustrian$p.value, digits = 2)) `). 

\newpage

#### Question 12
*So far, we’ve only been focused on ring weight. Let’s go back and make a histogram of rib weight. Why would testing a hypothesis about average rib weight be harder?*

```{r p1q12, echo = FALSE}
hist(money$Weight[money$Type == "Rib"],
    main = "Rib Weights",
    breaks = 30, 
    xlab = "Weight (g)"
    )
```

> Making predictions or testing hypotheses about rib weight would be difficult because they appear to follow a bimodal distribution. 

\newpage

### Part II

*Assume an experiment in which the number of plants in 16 experimental plots is counted as:* 

```{r plants}
plants <- c(8, 0, 3, 3, 4, 3, 2, 3, 3, 2, 4, 2, 3, 1, 4, 1)
```

*We want to model the number of plants in each plot as being distributed according to a Poisson distribution.*

#### Question 1
*Starting with the probability density function for the Poisson, manually derive the maximum likelihood estimate for $\lambda$, the parameter for the Poisson distribution.*

$$
\begin{aligned}
f(x\mid\lambda) &= \frac{e^{-\lambda}\lambda^{x}}{x!} \\
f(X_1, X_2...,X_n \mid \lambda) &= \prod_{i=1}^{n}\frac{e^{-\lambda}\lambda^{X_i}}{X_i!} \\
L(\lambda \mid X_1, X_2,...,X_n) &= \prod_{i=1}^{n}\frac{e^{-\lambda}\lambda^{X_i}}{X_i!} \\
LL &= \sum_{i=1}^{n} \left(ln \frac{e^{-\lambda}\lambda^{X_i}}{X_i!} \right) \\
LL &= \sum_{i=1}^{n} (ln \; e^{-\lambda} + ln \; \lambda^{X_i} -ln \; X_i!) \\
LL &= \sum_{i=1}^{n} (-\lambda + X_i \; ln \; \lambda - ln \; X_i!) \\
NLL &= \sum_{i=1}^{n} (\lambda - X_i \; ln \; \lambda + ln \; X_i!) \\
\frac{\partial NLL}{\partial \lambda} &= \sum_{i=1}^{n} \left(1- \frac{X_i}{\lambda} \right) \\
0 &= \sum_{i=1}^{n} \left(1- \frac{X_i}{\hat{\lambda}} \right) \\
0 &= n - \sum_{i=1}^{n} \left(\frac{X_i}{\hat{\lambda}} \right) \\
n &= \sum_{i=1}^{n} \left(\frac{X_i}{\hat{\lambda}} \right) \\
n &= \frac{1}{\hat{\lambda}} \sum_{i=1}^{n} X_i \\
\hat{\lambda} &= \frac{\sum_{i=1}^{n} X_i}{n}
\end{aligned}
$$

#### Question 2
*Write an R function to calculate the negative log-likelihood for this data as described by the Poisson distribution.*

> From question 1, we know the negative log-likelihood of a Poisson distribution is $NLL = \sum_{i=1}^{n} (\lambda - X_i \; ln \; \lambda + ln \; X_i!)$

```{r p2q2}
neg.ll <- function(x, lambda){
        result <- length(x)*lambda - sum(x)*log(lambda) + sum(log(factorial(x)))
        return(result)
}

# The non-try-hard version:
# neg.ll.v2 <- function(x, lambda){
#       result <- -sum(dpois(x, 
#                            lambda, 
#                            log = TRUE)
#                            )
#       return(result)
#       }

```

#### Question 3
*Using your function for the negative log-likelihood, calculate the MLE for $\lambda$ and the 95^th^ percentile confidence interval. What would the 99^th^ percentile confidence interval be?*

```{r p2q3 lambda tests, cache = TRUE}
# Define test lambda values
lambdaVals <- seq(min(plants),
                  max(plants),
                  by = 0.05
                  )

# Create vector to catch log likelihood values of test lambdas
plantLogLiks <- rep(0, length(lambdaVals))

# Run neg.ll() over all lambdaVals
for (i in 1:length(lambdaVals)){
        plantLogLiks[i] <- neg.ll(plants, lambdaVals[i])
}

# Use optimize() to determine the minimum value
plantMinLogLik <- optimize(f = neg.ll, x = plants, interval = lambdaVals)

# 95th percentile confidence interval
# Collect the positions of the lambda values whose negative log-likelihoods are
# within 1.92 of the minimum
vals95 <- which(plantLogLiks < plantMinLogLik$objective + 1.92)

# Use the first and last to select the corresponding lambda value
LL95 <- lambdaVals[vals95[1]]
UL95 <- lambdaVals[vals95[length(vals95)]]

# 99th percentile confidence interval
# Collect the positions of the lambda values whose negative log-likelihoods are
# within 3.32 of the minimum
vals99 <- which(plantLogLiks < plantMinLogLik$objective + 3.32)

# Use the first and last to select the corresponding lambda value
LL99 <- lambdaVals[vals99[1]]
UL99 <- lambdaVals[vals99[length(vals99)]]

```

> The calculated lambda for the plants per plot is `r mean(plants) `. The optimized lambda value with the lowest log-likelihood is `r round(plantMinLogLik$minimum, digits = 3) `, NLL = `r round(plantMinLogLik$objective, digits = 3) `.

> 95^th^ percentile confidence interval: (`r LL95`, `r UL95`) 

> 99^th^ percentile confidence interval: (`r LL99`, `r UL99`) 

#### Question 4
*Plot the likelihood over a range of parameter values and plot the boundaries of the 95^th^ and 99^th^ percentile confidence interval. Remember: The confidence interval is a range of parameter values, it is NOT the likelihood values itself.*

```{r p2q4 plot, echo = FALSE}
plot(lambdaVals,
     plantLogLiks,
     xlab = "Test Lambda Values",
     ylab = "Negative Log-Likelihood",
     main = "Negative Log-Likelihood Values for Average Plants per Plot", 
     pch = 1,
     cex = 0.9,
     cex.axis = 0.9
     )

abline(v = c(LL95, UL95), 
       lty = 2, 
       lwd = 1.5
       )

abline(v = c(LL99, UL99), 
       lty = 3, 
       lwd = 1.5
       )

points(x = plantMinLogLik$minimum, 
       y = plantMinLogLik$objective, 
       pch = 23, 
       bg = "cornflowerblue"
       )

legend("topright", 
       c("95% CI", "99% CI", "MLE"),
       lty = c(2, 3, NA), 
       lwd = c(1.5, 1.5, NA),
       pch = c(NA, NA, 23),
       pt.bg = c(NA, NA, "cornflowerblue"),
       bty = "n",
       inset = 0.01
       )

```